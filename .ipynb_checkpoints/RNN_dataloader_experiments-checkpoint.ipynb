{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T14:06:37.322684Z",
     "start_time": "2019-04-13T14:06:35.741487Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.utils import data\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from glob import iglob, glob\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-13T14:02:40.971Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"tensors = []\n",
    "for path in paths:\n",
    "    tensor = torch.load(path).numpy()\n",
    "    tensors.append(tensor)\n",
    "tensors = np.array(tensors).astype('float32')\n",
    "tensors.shape\n",
    "\n",
    "tensors = tensors.reshape((len(tensors), -1))\n",
    "print(tensors.shape)\n",
    "\n",
    "batch_size = 16\n",
    "seq_len = 128\n",
    "\n",
    "full_seq = tensors.shape[0] // (seq_len * batch_size) * (seq_len * batch_size)\n",
    "print(full_seq)\n",
    "\n",
    "tensors = tensors[:full_seq].reshape((batch_size, -1, tensors.shape[1]))\n",
    "print(tensors.shape)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-13T14:02:40.972Z"
    }
   },
   "outputs": [],
   "source": [
    "class S2FDatasetRAM(data.Dataset):\n",
    "    '''\n",
    "    Sequence of Frames to one frame dataset.\n",
    "    Load all data into RAM at once.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, datadir, seq_len):\n",
    "        '''\n",
    "        Initialization\n",
    "        Args:\n",
    "            datadir: directory of serialized tensors\n",
    "            seq_len: timestep length of tensors\n",
    "            batch_size: divide a sequence to n_batch sequences\n",
    "        '''\n",
    "        self.paths = glob(datadir + '/*.pkl')\n",
    "        path_num = len(self.paths)\n",
    "        full_seq = path_num // seq_len * seq_len\n",
    "        # only want full size batches\n",
    "        self.paths = self.paths[: full_seq]\n",
    "\n",
    "        self.seq_len = seq_len\n",
    "        # total length of all tensors\n",
    "        self.length = len(self.paths)\n",
    "\n",
    "        # load all tensor into RAM\n",
    "        tensors = []\n",
    "        for path in self.paths:\n",
    "            tensor = torch.load(path).numpy()\n",
    "            tensors.append(tensor)\n",
    "        tensors = np.array(tensors).astype('float32')\n",
    "        self.tensors = tensors.reshape((self.length, -1))\n",
    "\n",
    "    def __len__(self):\n",
    "        '''\n",
    "        Denotes the total number of samples\n",
    "        '''\n",
    "        return self.length - self.seq_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "        Generates one sample of data\n",
    "        '''\n",
    "        X = self.tensors[index: index+self.seq_len]\n",
    "        y = self.tensors[index+self.seq_len]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T14:06:42.731420Z",
     "start_time": "2019-04-13T14:06:42.570810Z"
    }
   },
   "outputs": [],
   "source": [
    "datadir = 'tensor_dataset/full_year_2018_15min/tensors'\n",
    "paths = glob(datadir + '/*.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T14:07:50.208069Z",
     "start_time": "2019-04-13T14:07:50.203082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35040"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-13T14:02:40.974Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = S2FDatasetRAM(datadir, 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-13T14:02:40.975Z"
    }
   },
   "outputs": [],
   "source": [
    "loader = data.DataLoader(dataset, shuffle=False , batch_size = 20)\n",
    "d_iter = iter(loader)\n",
    "a = d_iter.next()\n",
    "print(a[0].shape, a[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
