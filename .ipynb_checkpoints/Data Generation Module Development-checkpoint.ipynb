{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/logo_city.png\" align=\"right\" width=\"20%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation Module Development\n",
    "\n",
    "## 1. Goal\n",
    "\n",
    "The module should be something like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T08:45:25.494802Z",
     "start_time": "2019-03-29T08:45:23.096189Z"
    }
   },
   "outputs": [],
   "source": [
    "import timeslice                    \n",
    "import timeslice.source as source   \n",
    "import timeslice.rule  as rule      \n",
    "import timeslice.worker as worker\n",
    "import timeslice.viz as viz # to be done\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T08:45:25.590549Z",
     "start_time": "2019-03-29T08:45:25.496796Z"
    }
   },
   "outputs": [],
   "source": [
    "# set time split rule for dataset generation\n",
    "time_rule = rule.TimeSlice(stp='2017-05-01 00:00:00', etp='2017-05-02 00:00:00', freq='10min')\n",
    "\n",
    "# connect to database source\n",
    "taxi_db = source.DatabaseSource('cleaned_small_yellow_2017_full', time_rule)\n",
    "\n",
    "# initialize worker\n",
    "data_worker = worker.Worker(source=taxi_db, destin='data_test/monthly_data/may', rule=time_rule, viz=True)\n",
    "\n",
    "# generate dataset\n",
    "# data_worker.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T08:45:25.600524Z",
     "start_time": "2019-03-29T08:45:25.591548Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.date_range('2017-05-01 00:00:00', '2017-06-01 00:00:00', freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T09:13:50.943621Z",
     "start_time": "2019-03-29T08:57:02.371542Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import psycopg2\n",
    "\n",
    "def _construct_sql(stp:str, etp:str):\n",
    "        '''\n",
    "        A private helper function to construct sql query, called another\n",
    "        helper function _construct_split.\n",
    "\n",
    "        Args:\n",
    "            stp: datetime string, starting time point of a concurrent unit\n",
    "            etp: datatime string, end time point of a concurrent unit\n",
    "\n",
    "        Returns:\n",
    "            sql: a constructed query string\n",
    "        '''\n",
    "        pattern = re.compile(\n",
    "            '^([0-9]{4})-([0-1][0-9])-([0-3][0-9])\\s([0-1][0-9]|[2][0-3]):([0-5][0-9]):([0-5][0-9])$'\n",
    "        )\n",
    "        assert pattern.match(stp) and pattern.match(etp)\n",
    "\n",
    "        return (f\"select tripid,tpep_pickup_datetime,tpep_dropoff_datetime,pulocationid,dolocationid from cleaned_small_yellow_2017_full \"\n",
    "                f\"where tpep_pickup_datetime >= '{stp}' and tpep_dropoff_datetime < '{etp}';\")\n",
    "    \n",
    "\n",
    "\n",
    "bounds = pd.date_range('2017-05-01 00:00:00', '2017-06-01 00:00:00', freq='D')\n",
    "subs = list(zip(bounds[:-1], bounds[1:]))\n",
    "queries = {}\n",
    "\n",
    "host = 'localhost'\n",
    "dbname = 'taxi'\n",
    "user = 'postgres'\n",
    "\n",
    "conn = psycopg2.connect(f'host={host} dbname={dbname} user={user}')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# create sub interval queries\n",
    "for i, sub in enumerate(subs):\n",
    "    stp, etp = list(map(str, sub))\n",
    "    queries[i] = _construct_sql(stp, etp)\n",
    "\n",
    "dataframes = {}\n",
    "        \n",
    "for i, query in queries.items():\n",
    "    # dataframes[i] = pd.read_sql_query(query, conn)\n",
    "    cursor.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T10:06:24.293805Z",
     "start_time": "2019-03-29T09:49:52.235508Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import psycopg2\n",
    "from threading import Thread\n",
    "from multiprocessing import Process\n",
    "from queue import Queue\n",
    "\n",
    "def _construct_sql(stp:str, etp:str):\n",
    "        '''\n",
    "        A private helper function to construct sql query, called another\n",
    "        helper function _construct_split.\n",
    "\n",
    "        Args:\n",
    "            stp: datetime string, starting time point of a concurrent unit\n",
    "            etp: datatime string, end time point of a concurrent unit\n",
    "\n",
    "        Returns:\n",
    "            sql: a constructed query string\n",
    "        '''\n",
    "        pattern = re.compile(\n",
    "            '^([0-9]{4})-([0-1][0-9])-([0-3][0-9])\\s([0-1][0-9]|[2][0-3]):([0-5][0-9]):([0-5][0-9])$'\n",
    "        )\n",
    "        assert pattern.match(stp) and pattern.match(etp)\n",
    "\n",
    "        return (f\"select tripid,tpep_pickup_datetime,tpep_dropoff_datetime,pulocationid,dolocationid from cleaned_small_yellow_2017_full \"\n",
    "                f\"where tpep_pickup_datetime >= '{stp}' and tpep_dropoff_datetime < '{etp}';\")\n",
    "    \n",
    "\n",
    "\n",
    "def concurrent_read(id:int, df_pool:dict, query:str, conn):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(query)\n",
    "    \n",
    "    \n",
    "bounds = pd.date_range('2017-05-01 00:00:00', '2017-06-01 00:00:00', freq='D')\n",
    "subs = list(zip(bounds[:-1], bounds[1:]))\n",
    "queries = {}\n",
    "\n",
    "host = 'localhost'\n",
    "dbname = 'taxi'\n",
    "user = 'postgres'\n",
    "thread_pool = Queue()\n",
    "df_pool = Queue()\n",
    "\n",
    "conn = psycopg2.connect(f'host={host} dbname={dbname} user={user}')\n",
    "# create sub interval queries\n",
    "for i, sub in enumerate(subs):\n",
    "    stp, etp = list(map(str, sub))\n",
    "    queries[i] = _construct_sql(stp, etp)\n",
    "\n",
    "\n",
    "for i, query in queries.items():\n",
    "    t = Thread(target=concurrent_read, args=(i, df_pool, query, conn))\n",
    "    thread_pool.put(t)\n",
    "    t.start()\n",
    "\n",
    "\n",
    "while not thread_pool.empty():\n",
    "    p = thread_pool.get()\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T13:45:40.306131Z",
     "start_time": "2019-03-29T13:45:40.295160Z"
    }
   },
   "outputs": [],
   "source": [
    "# define function to return weekly-sliced time intervals\n",
    "def weekly_divide(stp:str, etp:str):\n",
    "    \n",
    "    bounds = pd.date_range(stp, etp, freq='1W-MON')\n",
    "    print(bounds[0], bounds[-1])\n",
    "    head_round = tail_round = None\n",
    "    if bounds[0] != stp:\n",
    "        head_round = (pd.Timestamp(stp), pd.Timestamp(bounds[0]))\n",
    "    if bounds[-1] != etp:\n",
    "        tail_round = (pd.Timestamp(bounds[-1]), pd.Timestamp(etp))\n",
    "    print('\\n\\n\\n')\n",
    "    subs = [head_round] + list(zip(bounds[:-1], bounds[1:])) + [tail_round]\n",
    "    \n",
    "    return subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T13:45:41.628617Z",
     "start_time": "2019-03-29T13:45:41.299473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-02 00:00:00 2017-05-29 00:00:00\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Timestamp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-2d17d0f6ad0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mweekly_divide\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'2017-01-01 00:00:00'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'2017-06-01 00:00:00'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-a3439d2baa44>\u001b[0m in \u001b[0;36mweekly_divide\u001b[1;34m(stp, etp)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mhead_round\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtail_round\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbounds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mstp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mhead_round\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTimestamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbounds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0metp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mtail_round\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTimestamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Timestamp' is not defined"
     ]
    }
   ],
   "source": [
    "weekly_divide('2017-01-01 00:00:00', '2017-06-01 00:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T13:27:46.351010Z",
     "start_time": "2019-03-29T13:27:46.346023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-01-01 00:00:00', freq='W-MON')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Timestamp('2017-01-01 00:00:00', freq='W-MON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T13:45:00.685078Z",
     "start_time": "2019-03-29T13:45:00.679094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1] + [2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
