{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/logo_city.png\" align=\"right\" width=\"20%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training A Graph State Prediction Network (GSPNet): Simplified version\n",
    "\n",
    "This notebook is a prototype on how to train a graph state prediction network using CNN and LSTM.\n",
    "The content is devided into __3__ parts:\n",
    "\n",
    "1. Data preprocessing\n",
    "2. Model building, Training and Tuning\n",
    "3. Prediction and per demand modifacation\n",
    "\n",
    "The model is built with [PyTorch](https://pytorch.org/).\n",
    "\n",
    "<p style='color: darkred'><strong>This version is simplified and most of intermediate explainatory codes and comments are removed except those directly contribute to generating images. For duck process, see the prototype version.</strong></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing\n",
    "\n",
    "### 1. Load Libraries and Data\n",
    "\n",
    "Load in the data. Check the data integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sqlalchemy\n",
    "import time\n",
    "import psycopg2\n",
    "import warnings\n",
    "import re\n",
    "import torch\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripid</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>pulocationid</th>\n",
       "      <th>dolocationid</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>trip_time</th>\n",
       "      <th>trip_avg_speed</th>\n",
       "      <th>trip_time_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35972297</td>\n",
       "      <td>2017-03-09 21:30:11</td>\n",
       "      <td>2017-03-09 21:44:20</td>\n",
       "      <td>148</td>\n",
       "      <td>48</td>\n",
       "      <td>4.06</td>\n",
       "      <td>1</td>\n",
       "      <td>18.36</td>\n",
       "      <td>00:14:09</td>\n",
       "      <td>17.215548</td>\n",
       "      <td>849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35972298</td>\n",
       "      <td>2017-03-09 21:47:00</td>\n",
       "      <td>2017-03-09 21:58:01</td>\n",
       "      <td>48</td>\n",
       "      <td>107</td>\n",
       "      <td>2.73</td>\n",
       "      <td>1</td>\n",
       "      <td>12.80</td>\n",
       "      <td>00:11:01</td>\n",
       "      <td>14.868381</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35972299</td>\n",
       "      <td>2017-03-09 22:01:08</td>\n",
       "      <td>2017-03-09 22:11:16</td>\n",
       "      <td>79</td>\n",
       "      <td>162</td>\n",
       "      <td>2.27</td>\n",
       "      <td>1</td>\n",
       "      <td>14.12</td>\n",
       "      <td>00:10:08</td>\n",
       "      <td>13.440789</td>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35972300</td>\n",
       "      <td>2017-03-09 22:16:05</td>\n",
       "      <td>2017-03-10 06:26:11</td>\n",
       "      <td>237</td>\n",
       "      <td>41</td>\n",
       "      <td>3.86</td>\n",
       "      <td>1</td>\n",
       "      <td>17.29</td>\n",
       "      <td>08:10:06</td>\n",
       "      <td>0.472557</td>\n",
       "      <td>29406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35972301</td>\n",
       "      <td>2017-03-31 06:31:53</td>\n",
       "      <td>2017-03-31 06:41:48</td>\n",
       "      <td>41</td>\n",
       "      <td>162</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1</td>\n",
       "      <td>13.30</td>\n",
       "      <td>00:09:55</td>\n",
       "      <td>20.873950</td>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tripid tpep_pickup_datetime tpep_dropoff_datetime  pulocationid  \\\n",
       "0  35972297  2017-03-09 21:30:11   2017-03-09 21:44:20           148   \n",
       "1  35972298  2017-03-09 21:47:00   2017-03-09 21:58:01            48   \n",
       "2  35972299  2017-03-09 22:01:08   2017-03-09 22:11:16            79   \n",
       "3  35972300  2017-03-09 22:16:05   2017-03-10 06:26:11           237   \n",
       "4  35972301  2017-03-31 06:31:53   2017-03-31 06:41:48            41   \n",
       "\n",
       "   dolocationid  trip_distance  passenger_count  total_amount trip_time  \\\n",
       "0            48           4.06                1         18.36  00:14:09   \n",
       "1           107           2.73                1         12.80  00:11:01   \n",
       "2           162           2.27                1         14.12  00:10:08   \n",
       "3            41           3.86                1         17.29  08:10:06   \n",
       "4           162           3.45                1         13.30  00:09:55   \n",
       "\n",
       "   trip_avg_speed  trip_time_sec  \n",
       "0       17.215548            849  \n",
       "1       14.868381            661  \n",
       "2       13.440789            608  \n",
       "3        0.472557          29406  \n",
       "4       20.873950            595  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.read_csv('dataset/nytaxi_yellow_2017_mar.csv')\n",
    "table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check table shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10222693, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check data:\n",
    "\n",
    "Ratio of trips last longer than 30 minutes: (better smaller than 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08854594381343546"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(table.loc[table['trip_time_sec'] > 1800].shape[0] / table.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project only needed columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripid</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>pulocationid</th>\n",
       "      <th>dolocationid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35972297</td>\n",
       "      <td>2017-03-09 21:30:11</td>\n",
       "      <td>2017-03-09 21:44:20</td>\n",
       "      <td>148</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35972298</td>\n",
       "      <td>2017-03-09 21:47:00</td>\n",
       "      <td>2017-03-09 21:58:01</td>\n",
       "      <td>48</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35972299</td>\n",
       "      <td>2017-03-09 22:01:08</td>\n",
       "      <td>2017-03-09 22:11:16</td>\n",
       "      <td>79</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35972300</td>\n",
       "      <td>2017-03-09 22:16:05</td>\n",
       "      <td>2017-03-10 06:26:11</td>\n",
       "      <td>237</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35972301</td>\n",
       "      <td>2017-03-31 06:31:53</td>\n",
       "      <td>2017-03-31 06:41:48</td>\n",
       "      <td>41</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tripid tpep_pickup_datetime tpep_dropoff_datetime  pulocationid  \\\n",
       "0  35972297  2017-03-09 21:30:11   2017-03-09 21:44:20           148   \n",
       "1  35972298  2017-03-09 21:47:00   2017-03-09 21:58:01            48   \n",
       "2  35972299  2017-03-09 22:01:08   2017-03-09 22:11:16            79   \n",
       "3  35972300  2017-03-09 22:16:05   2017-03-10 06:26:11           237   \n",
       "4  35972301  2017-03-31 06:31:53   2017-03-31 06:41:48            41   \n",
       "\n",
       "   dolocationid  \n",
       "0            48  \n",
       "1           107  \n",
       "2           162  \n",
       "3            41  \n",
       "4           162  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw four needed columns and a id column, then sort according to time.\n",
    "# the `tripid` column is for the sake of naming.\n",
    "tensor_gen = table.loc[:,['tripid',\n",
    "                          'tpep_pickup_datetime',\n",
    "                          'tpep_dropoff_datetime',\n",
    "                          'pulocationid', 'dolocationid']\n",
    "                      ] # the first sort condition rules\n",
    "tensor_gen.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Time Interval Preprocessing\n",
    "\n",
    "Create time interval and process original table to generate images.\n",
    "\n",
    "Change datetime columns from str type to Timestamp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tripid                            int64\n",
       "tpep_pickup_datetime     datetime64[ns]\n",
       "tpep_dropoff_datetime    datetime64[ns]\n",
       "pulocationid                      int64\n",
       "dolocationid                      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess datatime columns here\n",
    "# Very expensive operation, do once.\n",
    "tensor_gen['tpep_pickup_datetime'] = pd.to_datetime(tensor_gen['tpep_pickup_datetime'])\n",
    "tensor_gen['tpep_dropoff_datetime'] = pd.to_datetime(tensor_gen['tpep_dropoff_datetime'])\n",
    "\n",
    "tensor_gen.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to create time **intervals**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timesplit(stp: str, etp: str, freq='10min'):\n",
    "    '''\n",
    "    Create a DatetimeIndx interval.\n",
    "    \n",
    "    Params:\n",
    "        stp: string, starting time point, first left bound\n",
    "        etp: string, ending time point, last right bound\n",
    "        freq: frequency, time interval unit of the splice operation\n",
    "    The stp and etp must of pattern \"yyyy-mm-dd hh:mm:ss\", otherwise exception will be raised.\n",
    "    \n",
    "    Return:\n",
    "        A list of time intervals tuples,each item is a tuple of two\n",
    "        interval(i.e., pandas.core.indexes.datetimes.DatetimeIndex object)\n",
    "        For example, a possible return could be [(2017-01-01 00:00:00, 2017-01-01 00:10:00),\n",
    "                                                 (2017-01-01 00:10:00, 2017-01-01 00:20:00)]\n",
    "    '''\n",
    "    pattern = re.compile('^([0-9]{4})-([0-1][0-9])-([0-3][0-9])\\s([0-1][0-9]|[2][0-3]):([0-5][0-9]):([0-5][0-9])$')\n",
    "    if pattern.match(stp) and pattern.match(etp):\n",
    "        time_bounds = pd.date_range(stp, etp, freq=freq)\n",
    "        sub_intervals = list(zip(time_bounds[:-1], time_bounds[1:]))\n",
    "        print(len(time_bounds), len(sub_intervals))\n",
    "        return sub_intervals\n",
    "    else:\n",
    "        raise Exception('Provided time bound is of invalid format.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Location Preprocessing\n",
    "\n",
    "Preprocess location related information: mapping ids and locations, then generate adjacency matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape is: (265, 4)\n"
     ]
    }
   ],
   "source": [
    "# Load zone lookup table\n",
    "zones = pd.read_csv('dataset/taxi_zone_lookup.csv')\n",
    "print(f'shape is: {zones.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69, 4)\n"
     ]
    }
   ],
   "source": [
    "yellow_zone = zones.loc[zones['Borough'] == 'Manhattan']\n",
    "print(yellow_zone.shape)\n",
    "img_size = yellow_zone.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Generate Tensor: 3 matrices (layers) of connection\n",
    "\n",
    "Generate images that represent traffic states.\n",
    "\n",
    "Define functions to generate desired outcomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_snap_layers(table, bound):\n",
    "    '''\n",
    "    Generate Past layer, Now layer and Future layer for one snapshot.\n",
    "    Params:\n",
    "        table:\n",
    "        bounds:\n",
    "    Return:\n",
    "        PNF layers, a list.\n",
    "    '''\n",
    "    # left bound and right bound of time interval\n",
    "    assert type(bound) == tuple\n",
    "    left = bound[0]\n",
    "    right = bound[1]\n",
    "    \n",
    "    print(left, right)\n",
    "    \n",
    "    # no need to sort table indeed?\n",
    "    projected_table = table.loc[:, ['tripid',\n",
    "                                    'tpep_pickup_datetime',\n",
    "                                    'tpep_dropoff_datetime',\n",
    "                                    'pulocationid',\n",
    "                                    'dolocationid']]\n",
    "\n",
    "    # The condition of making snapshot should be:\n",
    "    # at least one temporal end of a trip should be within the bounds:\n",
    "    snap = projected_table.loc[\n",
    "        ((projected_table['tpep_pickup_datetime'] >= left) &\n",
    "         (projected_table['tpep_pickup_datetime'] < right)) |\n",
    "        ((projected_table['tpep_dropoff_datetime'] >= left) &\n",
    "         (projected_table['tpep_dropoff_datetime'] < right))]\n",
    "\n",
    "    # temp table to generate F,P,N layers\n",
    "    # keep snap intact\n",
    "    temp_snap = snap.copy()\n",
    "\n",
    "    # Use the interval to 'catch' corresponding trips.\n",
    "    # future layer\n",
    "    f_layer = temp_snap.loc[(temp_snap['tpep_pickup_datetime'] < right) &\n",
    "                             (temp_snap['tpep_pickup_datetime'] >= left) &\n",
    "                             (temp_snap['tpep_dropoff_datetime'] >= right)]\n",
    "    # past layer\n",
    "    p_layer = temp_snap.loc[(temp_snap['tpep_pickup_datetime'] < left) &\n",
    "                             (temp_snap['tpep_dropoff_datetime'] >= left) &\n",
    "                             (temp_snap['tpep_dropoff_datetime'] < right)]\n",
    "    # now layer\n",
    "    n_layer = temp_snap.loc[(temp_snap['tpep_pickup_datetime'] >= left) &\n",
    "                             (temp_snap['tpep_dropoff_datetime'] < right)]\n",
    "\n",
    "    # Their count should add up to total trips caught\n",
    "    assert temp_snap.shape[0] == f_layer.shape[0] + p_layer.shape[0] + n_layer.shape[0]\n",
    "\n",
    "    return p_layer, n_layer, f_layer\n",
    "\n",
    "\n",
    "# Function that combines layers to an image\n",
    "def gen_image(p_layer, n_layer, f_layer):\n",
    "    '''\n",
    "    Generate an image using given matrices.\n",
    "    Params:\n",
    "        p_layer: matrix of past layer\n",
    "        n_layer: matrix of now layer\n",
    "        f_layer: matrix of future layer\n",
    "    Return:\n",
    "        A PIL image.\n",
    "    '''\n",
    "    # create a snapshot\n",
    "    snapshot = np.zeros([img_size, img_size, 3], dtype='float64')\n",
    "\n",
    "    # unexpected zones\n",
    "    left_zones = set()\n",
    "\n",
    "    # future-Red: 0\n",
    "    for _, row in f_layer.iterrows():\n",
    "        try:\n",
    "            snapshot[mp[str(row['pulocationid'])], mp[str(row['dolocationid'])], 0] += 1\n",
    "        except Exception as e:\n",
    "            left_zones.add(str(row['pulocationid']))\n",
    "            left_zones.add(str(row['dolocationid']))\n",
    "\n",
    "    # past-Green: 1\n",
    "    for _, row in p_layer.iterrows():\n",
    "        try:\n",
    "            snapshot[mp[str(row['pulocationid'])], mp[str(row['dolocationid'])], 1] += 1\n",
    "        except Exception as e:\n",
    "            left_zones.add(str(row['pulocationid']))\n",
    "            left_zones.add(str(row['dolocationid']))\n",
    "\n",
    "    # now-Blue: 2\n",
    "    for _, row in n_layer.iterrows():\n",
    "        try:\n",
    "            snapshot[mp[str(row['pulocationid'])], mp[str(row['dolocationid'])], 2] += 1\n",
    "        except Exception as e:\n",
    "            left_zones.add(str(row['pulocationid']))\n",
    "            left_zones.add(str(row['dolocationid']))\n",
    "\n",
    "    # normalize\n",
    "    snapshot *= 255 // snapshot.max()\n",
    "    snapshot = snapshot.astype('uint8')\n",
    "    image = Image.fromarray(snapshot)\n",
    "    return image\n",
    "\n",
    "\n",
    "# generate tensor, because saving image as intermediate data is not efficient\n",
    "def gen_tensor(p_layer, n_layer, f_layer):\n",
    "    '''\n",
    "    Generate a tensor using given matrices.\n",
    "    Params:\n",
    "        p_layer: matrix of past layer\n",
    "        n_layer: matrix of now layer\n",
    "        f_layer: matrix of future layer\n",
    "    Return:\n",
    "        A torch tensor.\n",
    "    '''\n",
    "    # create a snapshot\n",
    "    snapshot = np.zeros([img_size, img_size, 3], dtype='float64')\n",
    "\n",
    "    # unexpected zones\n",
    "    left_zones = set()\n",
    "\n",
    "    # future-Red: 0\n",
    "    for _, row in f_layer.iterrows():\n",
    "        try:\n",
    "            snapshot[mp[str(row['pulocationid'])], mp[str(row['dolocationid'])], 0] += 1\n",
    "        except Exception as e:\n",
    "            left_zones.add(str(row['pulocationid']))\n",
    "            left_zones.add(str(row['dolocationid']))\n",
    "\n",
    "    # past-Green: 1\n",
    "    for _, row in p_layer.iterrows():\n",
    "        try:\n",
    "            snapshot[mp[str(row['pulocationid'])], mp[str(row['dolocationid'])], 1] += 1\n",
    "        except Exception as e:\n",
    "            left_zones.add(str(row['pulocationid']))\n",
    "            left_zones.add(str(row['dolocationid']))\n",
    "\n",
    "    # now-Blue: 2\n",
    "    for _, row in n_layer.iterrows():\n",
    "        try:\n",
    "            snapshot[mp[str(row['pulocationid'])], mp[str(row['dolocationid'])], 2] += 1\n",
    "        except Exception as e:\n",
    "            left_zones.add(str(row['pulocationid']))\n",
    "            left_zones.add(str(row['dolocationid']))\n",
    "\n",
    "    # normalize\n",
    "    snapshot *= 255 // snapshot.max()\n",
    "    snapshot = torch.from_numpy(snapshot)\n",
    "    return snapshot\n",
    "\n",
    "\n",
    "# Function that gets a specific layer of snapshot.\n",
    "def get_channel(image, layer:str):\n",
    "    '''\n",
    "    Get a layer of the snapshot.\n",
    "    Params:\n",
    "        image: PIL image\n",
    "        channel: one of R-F,G-P,B-N\n",
    "    Return:\n",
    "        single channel image\n",
    "    '''\n",
    "    assert layer in ['P', 'N', 'F']\n",
    "    namedict = {'P': 'G', 'N': 'B', 'F': 'R'}\n",
    "    chandict = {'R':0, 'G':1, 'B':2}\n",
    "    template = np.array(image)\n",
    "    chan = np.zeros([*template.shape], dtype='uint8')\n",
    "    chan[:,:,chandict[namedict[layer]]] = image.getchannel(namedict[layer])\n",
    "    chan = Image.fromarray(chan)\n",
    "    return chan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save data path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image save directory:\n",
    "visual_path = r'D:\\GITHUB\\GSPNet\\snapshots\\visualization'\n",
    "data_path = r'D:\\GITHUB\\GSPNet\\snapshots\\data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4465 4464\n",
      "2017-03-01 00:00:00 2017-03-01 00:10:00\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sorted_table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-f25a4477bdcf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tpep_dropoff_datetime'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tpep_dropoff_datetime'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbound\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimelist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mp_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_snap_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf'{data_path}\\\\nytaxi_yellow_2017_mar_d{i}.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-0949f239648d>\u001b[0m in \u001b[0;36mgen_snap_layers\u001b[1;34m(table, bound)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m# at least one temporal end of a trip should be within the bounds:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     snap = projected_table.loc[\n\u001b[1;32m---> 27\u001b[1;33m         ((sorted_table['tpep_pickup_datetime'] >= left) &\n\u001b[0m\u001b[0;32m     28\u001b[0m          (sorted_table['tpep_pickup_datetime'] < right)) |\n\u001b[0;32m     29\u001b[0m         ((sorted_table['tpep_dropoff_datetime'] >= left) &\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sorted_table' is not defined"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "timelist = timesplit('2017-03-01 00:00:00', '2017-04-01 00:00:00')\n",
    "# convert dtype for entire table here:\n",
    "table['tpep_pickup_datetime'] = pd.to_datetime(table['tpep_pickup_datetime'])\n",
    "table['tpep_dropoff_datetime'] = pd.to_datetime(table['tpep_dropoff_datetime'])\n",
    "for i, bound in enumerate(timelist):\n",
    "    p_layer, n_layer, f_layer = gen_snap_layers(table, bound)\n",
    "    tensor = gen_tensor(p_layer, n_layer, f_layer)\n",
    "    torch.save(tensor, f'{data_path}\\\\nytaxi_yellow_2017_mar_d{i}.pt')\n",
    "    image = gen_image(p_layer, n_layer, f_layer)\n",
    "    vimage = image.resize((690,690)) # multiply by factor of 100\n",
    "    vimage.save(f'{visual_path}\\\\nytaxi_yellow_2017_mar_v{i}.jpg')\n",
    "print(f'Image and tensor generation done in {time.time() - start :.2f} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
